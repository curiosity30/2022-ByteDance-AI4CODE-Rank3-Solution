{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, StandardScaler, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    '''自定义用来降低内存空间的函数'''\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../init_data/toUserA/train.csv'\n",
    "# test_path = '../init_data/toUserA/testa_nolabel.csv' # A榜测试集\n",
    "test_path = '../init_data/toUserB/testb_nolabel.csv'   # B榜测试集\n",
    "save_path = '../temp_data/'\n",
    "\n",
    "test = pd.read_csv(test_path)\n",
    "test.drop(['ID'], axis=1, inplace=True)\n",
    "print(test.shape)\n",
    "\n",
    "test_user_lst = test['userid'].unique().tolist()\n",
    "test_video_lst = test['videoid'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====数据预处理====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'userid'\n",
    "print(col)\n",
    "df_train = pd.read_csv(train_path, usecols=[col,'videoid'], chunksize=10000000)\n",
    "i = 0\n",
    "new_train = pd.DataFrame()\n",
    "for chunk in df_train:\n",
    "    i += 1\n",
    "    chunk = chunk[chunk['videoid'].isin(test_video_lst)][[col]]\n",
    "    new_train = new_train.append(chunk)\n",
    "    print(i, chunk.shape, new_train.shape)\n",
    "df_train = new_train\n",
    "print('===', df_train.shape, '===')\n",
    "del chunk; gc.collect()\n",
    "\n",
    "df_train.to_pickle(save_path+f'train_{col}.pkl')\n",
    "print(f'save train_{col} ok!')\n",
    "del df_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'tag'\n",
    "print(col)\n",
    "df_train = pd.read_csv(train_path, usecols=[col,'videoid'], chunksize=10000000)\n",
    "i = 0\n",
    "new_train = pd.DataFrame()\n",
    "for chunk in df_train:\n",
    "    i += 1\n",
    "    chunk = chunk[chunk['videoid'].isin(test_video_lst)][[col]]\n",
    "    new_train = new_train.append(chunk)\n",
    "    print(i, chunk.shape, new_train.shape)\n",
    "df_train = new_train\n",
    "print('===', df_train.shape, '===')\n",
    "del chunk; gc.collect()\n",
    "\n",
    "df_train.to_pickle(save_path+f'train_{col}.pkl')\n",
    "print(f'save train_{col} ok!')\n",
    "del df_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'videoid'\n",
    "print(col)\n",
    "df_train = pd.read_csv(train_path, usecols=[col], chunksize=10000000)\n",
    "i = 0\n",
    "new_train = pd.DataFrame()\n",
    "for chunk in df_train:\n",
    "    i += 1\n",
    "    chunk = chunk[chunk['videoid'].isin(test_video_lst)]\n",
    "    new_train = new_train.append(chunk)\n",
    "    print(i, chunk.shape, new_train.shape)\n",
    "df_train = new_train\n",
    "print('===', df_train.shape, '===')\n",
    "del chunk; gc.collect()\n",
    "\n",
    "df_train.to_pickle(save_path+f'train_{col}.pkl')\n",
    "print(f'save train_{col} ok!')\n",
    "del df_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'videoid':'category',\n",
    "    'is_like': 'int8', \n",
    "    'is_favourite': 'int8', \n",
    "    'is_share': 'int8', \n",
    "    'is_finish': 'int8',\n",
    "}\n",
    "label_cols = ['is_like','is_favourite','is_share','is_finish',]\n",
    "col = 'feedback'\n",
    "print(col)\n",
    "df_train = pd.read_csv(train_path, usecols=label_cols+['videoid'], dtype=dtype, chunksize=10000000)\n",
    "i = 0\n",
    "new_train = pd.DataFrame()\n",
    "for chunk in df_train:\n",
    "    i += 1\n",
    "    chunk = chunk[chunk['videoid'].isin(test_video_lst)]\n",
    "    new_train = new_train.append(chunk)\n",
    "    print(i, chunk.shape, new_train.shape)\n",
    "df_train = new_train[label_cols]\n",
    "print('===', df_train.shape, '===')\n",
    "del chunk; gc.collect()\n",
    "\n",
    "df_train.to_pickle(save_path+f'train_{col}.pkl')\n",
    "print(f'save train_{col} ok!')\n",
    "del df_train; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for col in ['userid', 'videoid', 'tag', 'feedback']:\n",
    "    print(col)\n",
    "    df_train = pd.concat([df_train, pd.read_pickle(save_path+f'train_{col}.pkl')], axis=1)\n",
    "\n",
    "df_train = df_train[df_train['userid'].isin(test_user_lst)]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "print(df_train.shape)\n",
    "\n",
    "df_train.to_pickle(save_path+'df_train_sp.pkl')\n",
    "print('save train ok!')\n",
    "\n",
    "del df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取筛选后的数据\n",
    "train = pd.read_pickle(save_path+'df_train_sp.pkl')\n",
    "print(train.shape)\n",
    "\n",
    "# label encoding\n",
    "for col in ['userid','videoid','tag']:\n",
    "    print(f'{col}: label encoding')\n",
    "    le = LabelEncoder()\n",
    "    le.fit(test[col])\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "\n",
    "# 减少内存 保存处理好后的 train & test\n",
    "train = reduce_mem_usage(train)\n",
    "train.to_pickle(save_path+'df_train_sp.pkl')\n",
    "print('save train ok!')\n",
    "\n",
    "test = reduce_mem_usage(test)\n",
    "test.to_pickle(save_path+'df_test_sp.pkl')\n",
    "print('save test ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 种类数\n",
    "# train[['userid','videoid','tag']].nunique()\n",
    "# userid      19274\n",
    "# videoid    222483\n",
    "# tag            25\n",
    "\n",
    "# # 缺失值 tag 836972\n",
    "# train.isnull().sum()\n",
    "\n",
    "# # 点击率\n",
    "# print(train['is_like'].mean())      # 0.01349\n",
    "# print(train['is_favourite'].mean()) # 0.00219\n",
    "# print(train['is_share'].mean())     # 0.00028\n",
    "# print(train['is_finish'].mean())    # 0.23156"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
