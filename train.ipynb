{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Layer, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 200)\n",
    "\n",
    "from dcn import DCN\n",
    "from utils import *\n",
    "from feature_engineer import *\n",
    "from gen_similarity_fea import generate_similarity_fea\n",
    "from gen_kmeans_fea import generate_kmeans_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kfold_model(x_train, y_train, test, features, feature_columns, model_path):\n",
    "    \n",
    "    # ========================= Hyper Parameters =======================\n",
    "    dnn_dropout = 0.3\n",
    "    hidden_units = [256, 128, 64]\n",
    "    LR = 1e-3\n",
    "    BATCH_SIZE = 8192 # 1024/2048/4096/8192/16384\n",
    "    epochs = 2\n",
    "    # ========================= END =======================\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_pred = np.zeros(shape=(test.shape[0],))\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kfold.split(x_train, y_train)):\n",
    "        print('************************************ {} ************************************'.format(str(i + 1)))\n",
    "\n",
    "        trn_x, trn_y = x_train[train_index], y_train[train_index]\n",
    "        val_x, val_y = x_train[valid_index], y_train[valid_index]\n",
    "\n",
    "        model = DCN(feature_columns, hidden_units=hidden_units, dnn_dropout=dnn_dropout)\n",
    "        model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=LR), metrics=[binary_crossentropy,])\n",
    "        model.fit(\n",
    "            trn_x,\n",
    "            trn_y,\n",
    "            epochs=2,\n",
    "            callbacks=[EarlyStopping(monitor='val_binary_crossentropy', patience=1, restore_best_weights=True, mode='min')],  # checkpoint,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            # validation_split=0.1,\n",
    "            validation_data=(val_x, val_y),\n",
    "        )\n",
    "        del trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "\n",
    "        print(f'fold_{i+1} model predict')\n",
    "        test_pred_fold = model.predict(test[features].values.astype('int32'), batch_size=BATCH_SIZE)\n",
    "        test_pred += (test_pred_fold.squeeze() / kfold.n_splits)\n",
    "        del test_pred_fold; gc.collect()\n",
    "\n",
    "        model.save_weights(model_path+f'DCN_fold_{i+1}.h5')\n",
    "        print(f'save fold_{i+1} model ok!')\n",
    "        del model; gc.collect()\n",
    "\n",
    "        print(f'fold_{i+1} train finish!')\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=2022)\n",
    "id_col = 'ID'\n",
    "target = 'is_finish'\n",
    "\n",
    "useless_cols = [id_col, target, 'is_like','is_favourite','is_share']\n",
    "dense_features = []\n",
    "sparse_features = ['userid','videoid','tag']\n",
    "EMBED_DIM = 16\n",
    "\n",
    "# ==== feature preparation =====\n",
    "N_COMPONENT = 32\n",
    "USER_CLUSTER_NUM = 16\n",
    "VIDEO_CLUSTER_NUM = 48\n",
    "generate_similarity_fea(n_component=N_COMPONENT)\n",
    "generate_kmeans_fea(N_COMPONENT, USER_CLUSTER_NUM, VIDEO_CLUSTER_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== load test data =====\n",
    "test_path = '../temp_data/df_test_sp.pkl'\n",
    "test = pd.read_pickle(test_path)\n",
    "print(test.shape)\n",
    "\n",
    "# ==== load train data =====\n",
    "train_data_path = '../temp_data/df_train_sp.pkl'\n",
    "train = pd.read_pickle(train_data_path)\n",
    "train = reduce_mem_usage(train)\n",
    "print(train.shape)\n",
    "print(train['tag'].isnull().sum())\n",
    "\n",
    "# video的反馈特征\n",
    "video_fb_path = '../temp_data/video_stat_v1.pkl'\n",
    "make_feedback_stat_fea(train, save_path=video_fb_path, group_fea='videoid')\n",
    "\n",
    "# user对于tag的反馈统计特征\n",
    "usertag_path = '../temp_data/user_tag_stat_v1.pkl'\n",
    "make_user_tag_stat_fea(train, save_path=usertag_path)\n",
    "\n",
    "# ==== concat train & test data =====\n",
    "# data = pd.concat([train, test],axis=0)\n",
    "data = train.append(test)\n",
    "data.drop(['is_like','is_favourite','is_share'], axis=1, inplace=True)\n",
    "print('all data shape: ', data.shape)\n",
    "data = reduce_mem_usage(data)\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "data = data.reset_index(drop=True).reset_index()\n",
    "data.sort_values(by=['userid','videoid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================ALL Feature Engineer=========================================\n",
    "data, sparse_features, dense_features = make_feature_engineer(data, sparse_features, dense_features)\n",
    "\n",
    "# ===================================Feature Columns=========================================\n",
    "# dense encode\n",
    "print('dense features NUM: ', len(dense_features))\n",
    "print('dense features:', dense_features)\n",
    "data = dense_fea_encode(data, dense_features=dense_features)\n",
    "data = bin_encode(data, bin_cols=dense_features, bin_num=32)\n",
    "\n",
    "# sparse encode\n",
    "print('sparse feature NUM: ', len(sparse_features))\n",
    "print('sparse features:', sparse_features)\n",
    "\n",
    "features = sparse_features + dense_features\n",
    "feature_columns = [sparseFeature(feat, int(data[feat].max())+1, embed_dim=EMBED_DIM) for feat in features]\n",
    "print('feature num:', len(features))\n",
    "print('features:', features)\n",
    "\n",
    "# ===================================SPLIT DATA=========================================\n",
    "x_train = data[data[target].notna()][features].values.astype('int32')\n",
    "y_train = data[data[target].notna()][target].values.astype('int32')\n",
    "test = data[data[target].isna()]\n",
    "print(x_train.shape, test.shape)\n",
    "del data; gc.collect()\n",
    "# test_fe_path = '../temp_data/df_test_fe.pkl'\n",
    "# test.to_pickle(test_fe_path)\n",
    "# print('save feature engineer test data!')\n",
    "\n",
    "# ===================================TRAIN MODEL=========================================\n",
    "model_path = './model/'\n",
    "test_pred = train_kfold_model(x_train, y_train, test, features, feature_columns, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_path = '../result/'\n",
    "file_name = 'result.csv'\n",
    "\n",
    "sub = test[['index']].copy()\n",
    "sub['is_finish'] = test_pred\n",
    "sub.sort_values(by=['index'], inplace=True)\n",
    "sub['index'] = list(range(sub.shape[0]))\n",
    "sub.columns = ['ID','is_finish']\n",
    "print(sub.shape)\n",
    "\n",
    "sub.to_csv(submit_path+file_name, index=False)\n",
    "print(f'generate submitfile: {file_name} ok!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b榜\n",
    "- 【0.4683】五折DCN 最好版本的特征 19个 \n",
    "    - mean=4567 | 4561 4564 4567 4577 4567(lr=2e-3,bs=8192,drop=0.4)【0.4683】\n",
    "    - mean=4554 | 4553 4555 4551 4564 4551(lr=1e-3,bs=8192,drop=0.4)\n",
    "    - mean=4555 | 4552 4557 4559 4552 4555(lr=1e-3,bs=8192,drop=0.5,kfold=2022)\n",
    "- 【0.4670】五折DCN 增加聚类特征(user 16类/video 64类) 21个 \n",
    "    - mean=4548 | 4549 4544 4543 4562 4545(lr=1e-3,bs=8192,drop=0.3)\n",
    "- 【0.4640】五折DCN 增加聚类特征(user 16类/video 64类) 21个 \n",
    "    - mean=4505 | 4506 4501 4506 4507 4507(lr=1e-3,bs=8192,drop=0.3)\n",
    "    - mean=4502 | 4502 4498 4503 4505 4502(lr=1e-3,bs=8192,drop=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4442a059423b1d8cb2d566f1d7a9e596fd1852f4b9b9e9d6f69b72f942b31330"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
